{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as r\n",
    "from datetime import *     \n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils.DataLoader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-25T17:50:10.81222Z</td>\n",
       "      <td>-2.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-25T17:55:19.800911Z</td>\n",
       "      <td>-2.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-25T18:00:34.410826Z</td>\n",
       "      <td>-2.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-25T18:05:43.303884Z</td>\n",
       "      <td>-2.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-12-25T18:10:57.930353Z</td>\n",
       "      <td>-2.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>2024-12-28T05:20:38.736164Z</td>\n",
       "      <td>-2.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>2024-12-28T05:21:05.116032Z</td>\n",
       "      <td>-2.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>2024-12-28T05:21:32.13423Z</td>\n",
       "      <td>-2.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>2024-12-28T05:26:45.716006Z</td>\n",
       "      <td>-2.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>2024-12-28T05:31:52.121195Z</td>\n",
       "      <td>-2.889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>651 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time  result\n",
       "1     2024-12-25T17:50:10.81222Z  -2.098\n",
       "2    2024-12-25T17:55:19.800911Z  -2.064\n",
       "3    2024-12-25T18:00:34.410826Z  -2.036\n",
       "4    2024-12-25T18:05:43.303884Z  -2.017\n",
       "5    2024-12-25T18:10:57.930353Z  -2.001\n",
       "..                           ...     ...\n",
       "647  2024-12-28T05:20:38.736164Z  -2.928\n",
       "648  2024-12-28T05:21:05.116032Z  -2.927\n",
       "649   2024-12-28T05:21:32.13423Z  -2.925\n",
       "650  2024-12-28T05:26:45.716006Z  -2.911\n",
       "651  2024-12-28T05:31:52.121195Z  -2.889\n",
       "\n",
       "[651 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/test_data.csv')\n",
    "df = df.iloc[:, [0, 1]].reset_index(drop=True)\n",
    "df.columns = [\"time\", \"result\"]\n",
    "df = df.drop(0, axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>rolling_mean_3</th>\n",
       "      <th>rolling_std_3</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.036</td>\n",
       "      <td>-2.064</td>\n",
       "      <td>-2.098</td>\n",
       "      <td>-2.039000</td>\n",
       "      <td>0.023643</td>\n",
       "      <td>-2.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>57</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.017</td>\n",
       "      <td>-2.036</td>\n",
       "      <td>-2.064</td>\n",
       "      <td>-2.018000</td>\n",
       "      <td>0.017521</td>\n",
       "      <td>-2.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.001</td>\n",
       "      <td>-2.017</td>\n",
       "      <td>-2.036</td>\n",
       "      <td>-2.000333</td>\n",
       "      <td>0.017010</td>\n",
       "      <td>-1.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.983</td>\n",
       "      <td>-2.001</td>\n",
       "      <td>-2.017</td>\n",
       "      <td>-1.978000</td>\n",
       "      <td>0.025865</td>\n",
       "      <td>-1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-1.983</td>\n",
       "      <td>-2.001</td>\n",
       "      <td>-1.948667</td>\n",
       "      <td>0.035019</td>\n",
       "      <td>-1.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.93</td>\n",
       "      <td>-2.932</td>\n",
       "      <td>-2.932</td>\n",
       "      <td>-2.930000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>-2.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.928</td>\n",
       "      <td>-2.93</td>\n",
       "      <td>-2.932</td>\n",
       "      <td>-2.928333</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>-2.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.927</td>\n",
       "      <td>-2.928</td>\n",
       "      <td>-2.93</td>\n",
       "      <td>-2.926667</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>-2.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>45</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.925</td>\n",
       "      <td>-2.927</td>\n",
       "      <td>-2.928</td>\n",
       "      <td>-2.921000</td>\n",
       "      <td>0.008718</td>\n",
       "      <td>-2.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>52</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.911</td>\n",
       "      <td>-2.925</td>\n",
       "      <td>-2.927</td>\n",
       "      <td>-2.908333</td>\n",
       "      <td>0.018148</td>\n",
       "      <td>-2.889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month  day  day_of_week  hour  minute  second  hour_sin  \\\n",
       "4    2024     12   25            2    18       5      43 -1.000000   \n",
       "5    2024     12   25            2    18      10      57 -1.000000   \n",
       "6    2024     12   25            2    18      16      13 -1.000000   \n",
       "7    2024     12   25            2    18      21      27 -1.000000   \n",
       "8    2024     12   25            2    18      26      36 -1.000000   \n",
       "..    ...    ...  ...          ...   ...     ...     ...       ...   \n",
       "647  2024     12   28            5     5      20      38  0.965926   \n",
       "648  2024     12   28            5     5      21       5  0.965926   \n",
       "649  2024     12   28            5     5      21      32  0.965926   \n",
       "650  2024     12   28            5     5      26      45  0.965926   \n",
       "651  2024     12   28            5     5      31      52  0.965926   \n",
       "\n",
       "         hour_cos  day_of_week_sin  day_of_week_cos     month_sin  month_cos  \\\n",
       "4   -1.836970e-16         0.974928        -0.222521 -2.449294e-16        1.0   \n",
       "5   -1.836970e-16         0.974928        -0.222521 -2.449294e-16        1.0   \n",
       "6   -1.836970e-16         0.974928        -0.222521 -2.449294e-16        1.0   \n",
       "7   -1.836970e-16         0.974928        -0.222521 -2.449294e-16        1.0   \n",
       "8   -1.836970e-16         0.974928        -0.222521 -2.449294e-16        1.0   \n",
       "..            ...              ...              ...           ...        ...   \n",
       "647  2.588190e-01        -0.974928        -0.222521 -2.449294e-16        1.0   \n",
       "648  2.588190e-01        -0.974928        -0.222521 -2.449294e-16        1.0   \n",
       "649  2.588190e-01        -0.974928        -0.222521 -2.449294e-16        1.0   \n",
       "650  2.588190e-01        -0.974928        -0.222521 -2.449294e-16        1.0   \n",
       "651  2.588190e-01        -0.974928        -0.222521 -2.449294e-16        1.0   \n",
       "\n",
       "      lag_1   lag_2   lag_3  rolling_mean_3  rolling_std_3  result  \n",
       "4    -2.036  -2.064  -2.098       -2.039000       0.023643  -2.017  \n",
       "5    -2.017  -2.036  -2.064       -2.018000       0.017521  -2.001  \n",
       "6    -2.001  -2.017  -2.036       -2.000333       0.017010  -1.983  \n",
       "7    -1.983  -2.001  -2.017       -1.978000       0.025865   -1.95  \n",
       "8     -1.95  -1.983  -2.001       -1.948667       0.035019  -1.913  \n",
       "..      ...     ...     ...             ...            ...     ...  \n",
       "647   -2.93  -2.932  -2.932       -2.930000       0.002000  -2.928  \n",
       "648  -2.928   -2.93  -2.932       -2.928333       0.001528  -2.927  \n",
       "649  -2.927  -2.928   -2.93       -2.926667       0.001528  -2.925  \n",
       "650  -2.925  -2.927  -2.928       -2.921000       0.008718  -2.911  \n",
       "651  -2.911  -2.925  -2.927       -2.908333       0.018148  -2.889  \n",
       "\n",
       "[648 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataLoader.transform_data(df)\n",
    "df = DataLoader.order_df(df)\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # Last timestep output\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['result']).values\n",
    "y = df['result'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 3\n",
    "\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    for i in range(seq_length, len(X)):\n",
    "        X_seq.append(X[i-seq_length:i])\n",
    "        y_seq.append(y[i])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X, y, sequence_length)\n",
    "\n",
    "# Manual train-test split\n",
    "split_idx = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split_idx], X_seq[split_idx:]\n",
    "y_train, y_test = y_seq[:split_idx], y_seq[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_seq.shape[2]\n",
    "hidden_size = 64\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model = LSTMModel(input_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(LSTM_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 2.9716\n",
      "Epoch [20/50], Loss: 2.9412\n",
      "Epoch [30/50], Loss: 2.9509\n",
      "Epoch [40/50], Loss: 2.9663\n",
      "Epoch [50/50], Loss: 2.9347\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    LSTM_model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = LSTM_model(X_batch).squeeze()\n",
    "        loss = criterion(outputs, y_batch.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimesFM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (4.52.0.dev0)\n",
      "Requirement already satisfied: accelerate in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (1.6.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/prasunbanerjee/.local/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Users/prasunbanerjee/.local/lib/python3.12/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (4.52.0.dev0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/prasunbanerjee/.local/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /private/var/folders/4v/q1spznf91t36ybznjd9h0g480000gn/T/pip-req-build-u_83vd68\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /private/var/folders/4v/q1spznf91t36ybznjd9h0g480000gn/T/pip-req-build-u_83vd68\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit ebbe9b12dd75b69f92100d684c47f923ee262a93\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/prasunbanerjee/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from requests->transformers==4.52.0.dev0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from requests->transformers==4.52.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from requests->transformers==4.52.0.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages (from requests->transformers==4.52.0.dev0) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --pre transformers\n",
    "%pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/SecooraVenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimesFmModelForPrediction(\n",
       "  (decoder): TimesFmModel(\n",
       "    (input_ff_layer): TimesFmResidualBlock(\n",
       "      (input_layer): Linear(in_features=64, out_features=1280, bias=True)\n",
       "      (activation): SiLU()\n",
       "      (output_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (residual_layer): Linear(in_features=64, out_features=1280, bias=True)\n",
       "    )\n",
       "    (freq_emb): Embedding(3, 1280)\n",
       "    (layers): ModuleList(\n",
       "      (0-49): 50 x TimesFmDecoderLayer(\n",
       "        (self_attn): TimesFmAttention(\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (o_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp): TimesFmMLP(\n",
       "          (gate_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (down_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (input_layernorm): TimesFmRMSNorm((1280,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (horizon_ff_layer): TimesFmResidualBlock(\n",
       "    (input_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (activation): SiLU()\n",
       "    (output_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (residual_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TimesFmModelForPrediction\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = TimesFmModelForPrediction.from_pretrained(\n",
    "    \"google/timesfm-2.0-500m-pytorch\",\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=device\n",
    ")\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SecooraVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
